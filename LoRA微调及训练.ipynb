{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "33364619-4768-4837-ad1c-2b72edc0f957",
      "metadata": {
        "id": "33364619-4768-4837-ad1c-2b72edc0f957"
      },
      "source": [
        "## 安装必要的库"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3b4e7d63-f337-4b40-840e-77678f29ef1c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "3b4e7d63-f337-4b40-840e-77678f29ef1c",
        "outputId": "c12fbe3d-1c27-427c-a25b-8d99fbdf8763",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: timm in /usr/local/lib/python3.10/dist-packages (1.0.12)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from timm) (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from timm) (0.20.1+cu121)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from timm) (6.0.2)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (from timm) (0.27.1)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from timm) (0.5.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (2024.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (24.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->timm) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (3.1.5)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->timm) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (11.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->timm) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (2024.12.14)\n",
            "Collecting fairscale\n",
            "  Downloading fairscale-0.4.13.tar.gz (266 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m266.3/266.3 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from fairscale) (2.5.1+cu121)\n",
            "Requirement already satisfied: numpy>=1.22.0 in /usr/local/lib/python3.10/dist-packages (from fairscale) (1.26.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->fairscale) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->fairscale) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->fairscale) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->fairscale) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->fairscale) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->fairscale) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.8.0->fairscale) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->fairscale) (3.0.2)\n",
            "Building wheels for collected packages: fairscale\n",
            "  Building wheel for fairscale (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fairscale: filename=fairscale-0.4.13-py3-none-any.whl size=332156 sha256=dbdb5446e15bb32d881d7977b1703a039a2fe912b08d8fdd0c1ecadc3502eb7a\n",
            "  Stored in directory: /root/.cache/pip/wheels/78/a4/c0/fb0a7ef03cff161611c3fa40c6cf898f76e58ec421b88e8cb3\n",
            "Successfully built fairscale\n",
            "Installing collected packages: fairscale\n",
            "Successfully installed fairscale-0.4.13\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.47.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.27.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.5.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.12.14)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2024.12.14)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (1.2.1)\n",
            "Requirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.2)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.5.1+cu121)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.27.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.5.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (2024.10.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.5)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2024.12.14)\n",
            "Requirement already satisfied: diffusers in /usr/local/lib/python3.10/dist-packages (0.32.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.10/dist-packages (from diffusers) (8.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from diffusers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from diffusers) (0.27.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from diffusers) (1.26.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from diffusers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from diffusers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from diffusers) (0.5.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from diffusers) (11.1.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.2->diffusers) (2024.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.2->diffusers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.2->diffusers) (6.0.2)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.2->diffusers) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.2->diffusers) (4.12.2)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata->diffusers) (3.21.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers) (2024.12.14)\n",
            "Collecting einop\n",
            "  Downloading einop-0.0.1-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: einops>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from einop) (0.8.0)\n",
            "Downloading einop-0.0.1-py3-none-any.whl (3.0 kB)\n",
            "Installing collected packages: einop\n",
            "Successfully installed einop-0.0.1\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (0.5.1)\n",
            "Collecting voluptuous\n",
            "  Downloading voluptuous-0.15.2-py3-none-any.whl.metadata (20 kB)\n",
            "Downloading voluptuous-0.15.2-py3-none-any.whl (31 kB)\n",
            "Installing collected packages: voluptuous\n",
            "Successfully installed voluptuous-0.15.2\n",
            "Requirement already satisfied: jax in /usr/local/lib/python3.10/dist-packages (0.4.33)\n",
            "Requirement already satisfied: jaxlib<=0.4.33,>=0.4.33 in /usr/local/lib/python3.10/dist-packages (from jax) (0.4.33)\n",
            "Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from jax) (0.4.1)\n",
            "Requirement already satisfied: numpy>=1.24 in /usr/local/lib/python3.10/dist-packages (from jax) (1.26.4)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.10/dist-packages (from jax) (3.4.0)\n",
            "Requirement already satisfied: scipy>=1.10 in /usr/local/lib/python3.10/dist-packages (from jax) (1.13.1)\n",
            "Requirement already satisfied: jaxlib in /usr/local/lib/python3.10/dist-packages (0.4.33)\n",
            "Requirement already satisfied: scipy>=1.10 in /usr/local/lib/python3.10/dist-packages (from jaxlib) (1.13.1)\n",
            "Requirement already satisfied: numpy>=1.24 in /usr/local/lib/python3.10/dist-packages (from jaxlib) (1.26.4)\n",
            "Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from jaxlib) (0.4.1)\n",
            "Requirement already satisfied: peft in /usr/local/lib/python3.10/dist-packages (0.14.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from peft) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from peft) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from peft) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from peft) (6.0.2)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from peft) (2.5.1+cu121)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from peft) (4.47.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from peft) (4.67.1)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from peft) (1.2.1)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from peft) (0.5.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.25.0 in /usr/local/lib/python3.10/dist-packages (from peft) (0.27.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.0->peft) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.0->peft) (2024.10.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.0->peft) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.0->peft) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.1.5)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.13.0->peft) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->peft) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers->peft) (0.21.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13.0->peft) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.25.0->peft) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.25.0->peft) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.25.0->peft) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.25.0->peft) (2024.12.14)\n",
            "Collecting deepface==0.0.90\n",
            "  Downloading deepface-0.0.90-py3-none-any.whl.metadata (26 kB)\n",
            "Requirement already satisfied: requests>=2.27.1 in /usr/local/lib/python3.10/dist-packages (from deepface==0.0.90) (2.32.3)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from deepface==0.0.90) (1.26.4)\n",
            "Requirement already satisfied: pandas>=0.23.4 in /usr/local/lib/python3.10/dist-packages (from deepface==0.0.90) (2.2.2)\n",
            "Requirement already satisfied: gdown>=3.10.1 in /usr/local/lib/python3.10/dist-packages (from deepface==0.0.90) (5.2.0)\n",
            "Requirement already satisfied: tqdm>=4.30.0 in /usr/local/lib/python3.10/dist-packages (from deepface==0.0.90) (4.67.1)\n",
            "Requirement already satisfied: Pillow>=5.2.0 in /usr/local/lib/python3.10/dist-packages (from deepface==0.0.90) (11.1.0)\n",
            "Requirement already satisfied: opencv-python>=4.5.5.64 in /usr/local/lib/python3.10/dist-packages (from deepface==0.0.90) (4.10.0.84)\n",
            "Requirement already satisfied: tensorflow>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from deepface==0.0.90) (2.17.1)\n",
            "Requirement already satisfied: keras>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from deepface==0.0.90) (3.5.0)\n",
            "Requirement already satisfied: Flask>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from deepface==0.0.90) (3.1.0)\n",
            "Collecting mtcnn>=0.1.0 (from deepface==0.0.90)\n",
            "  Downloading mtcnn-1.0.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting retina-face>=0.0.1 (from deepface==0.0.90)\n",
            "  Downloading retina_face-0.0.17-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting fire>=0.4.0 (from deepface==0.0.90)\n",
            "  Downloading fire-0.7.0.tar.gz (87 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.2/87.2 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gunicorn>=20.1.0 (from deepface==0.0.90)\n",
            "  Downloading gunicorn-23.0.0-py3-none-any.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from fire>=0.4.0->deepface==0.0.90) (2.5.0)\n",
            "Requirement already satisfied: Werkzeug>=3.1 in /usr/local/lib/python3.10/dist-packages (from Flask>=1.1.2->deepface==0.0.90) (3.1.3)\n",
            "Requirement already satisfied: Jinja2>=3.1.2 in /usr/local/lib/python3.10/dist-packages (from Flask>=1.1.2->deepface==0.0.90) (3.1.5)\n",
            "Requirement already satisfied: itsdangerous>=2.2 in /usr/local/lib/python3.10/dist-packages (from Flask>=1.1.2->deepface==0.0.90) (2.2.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.10/dist-packages (from Flask>=1.1.2->deepface==0.0.90) (8.1.8)\n",
            "Requirement already satisfied: blinker>=1.9 in /usr/local/lib/python3.10/dist-packages (from Flask>=1.1.2->deepface==0.0.90) (1.9.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown>=3.10.1->deepface==0.0.90) (4.12.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown>=3.10.1->deepface==0.0.90) (3.16.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gunicorn>=20.1.0->deepface==0.0.90) (24.2)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras>=2.2.0->deepface==0.0.90) (1.4.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=2.2.0->deepface==0.0.90) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=2.2.0->deepface==0.0.90) (0.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras>=2.2.0->deepface==0.0.90) (3.12.1)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=2.2.0->deepface==0.0.90) (0.13.1)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.10/dist-packages (from keras>=2.2.0->deepface==0.0.90) (0.4.1)\n",
            "Requirement already satisfied: joblib>=1.4.2 in /usr/local/lib/python3.10/dist-packages (from mtcnn>=0.1.0->deepface==0.0.90) (1.4.2)\n",
            "Collecting lz4>=4.3.3 (from mtcnn>=0.1.0->deepface==0.0.90)\n",
            "  Downloading lz4-4.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.23.4->deepface==0.0.90) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.23.4->deepface==0.0.90) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.23.4->deepface==0.0.90) (2024.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.27.1->deepface==0.0.90) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.27.1->deepface==0.0.90) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.27.1->deepface==0.0.90) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.27.1->deepface==0.0.90) (2024.12.14)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface==0.0.90) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface==0.0.90) (24.12.23)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface==0.0.90) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface==0.0.90) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface==0.0.90) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface==0.0.90) (3.4.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface==0.0.90) (4.25.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface==0.0.90) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface==0.0.90) (1.17.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface==0.0.90) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface==0.0.90) (1.17.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface==0.0.90) (1.69.0)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface==0.0.90) (2.17.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface==0.0.90) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow>=1.9.0->deepface==0.0.90) (0.45.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=3.1.2->Flask>=1.1.2->deepface==0.0.90) (3.0.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow>=1.9.0->deepface==0.0.90) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow>=1.9.0->deepface==0.0.90) (0.7.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown>=3.10.1->deepface==0.0.90) (2.6)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown>=3.10.1->deepface==0.0.90) (1.7.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=2.2.0->deepface==0.0.90) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=2.2.0->deepface==0.0.90) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=2.2.0->deepface==0.0.90) (0.1.2)\n",
            "Downloading deepface-0.0.90-py3-none-any.whl (97 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.1/97.1 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gunicorn-23.0.0-py3-none-any.whl (85 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.0/85.0 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mtcnn-1.0.0-py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m33.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading retina_face-0.0.17-py3-none-any.whl (25 kB)\n",
            "Downloading lz4-4.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m57.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: fire\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fire: filename=fire-0.7.0-py3-none-any.whl size=114249 sha256=c584430891d2d439568b6dffc44d17e22c4d9dfe5c15c0ab8c0d81dd9c743ac5\n",
            "  Stored in directory: /root/.cache/pip/wheels/19/39/2f/2d3cadc408a8804103f1c34ddd4b9f6a93497b11fa96fe738e\n",
            "Successfully built fire\n",
            "Installing collected packages: lz4, gunicorn, fire, mtcnn, retina-face, deepface\n",
            "Successfully installed deepface-0.0.90 fire-0.7.0 gunicorn-23.0.0 lz4-4.3.3 mtcnn-1.0.0 retina-face-0.0.17\n",
            "Collecting tensorflow==2.9.0\n",
            "  Downloading tensorflow-2.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.9.0) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.9.0) (1.6.3)\n",
            "Collecting flatbuffers<2,>=1.12 (from tensorflow==2.9.0)\n",
            "  Downloading flatbuffers-1.12-py2.py3-none-any.whl.metadata (872 bytes)\n",
            "Collecting gast<=0.4.0,>=0.2.1 (from tensorflow==2.9.0)\n",
            "  Downloading gast-0.4.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.9.0) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.9.0) (1.69.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.9.0) (3.12.1)\n",
            "Collecting keras<2.10.0,>=2.9.0rc0 (from tensorflow==2.9.0)\n",
            "  Downloading keras-2.9.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting keras-preprocessing>=1.1.1 (from tensorflow==2.9.0)\n",
            "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl.metadata (1.9 kB)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.9.0) (18.1.1)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.9.0) (1.26.4)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.9.0) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.9.0) (24.2)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.9.0) (4.25.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.9.0) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.9.0) (1.17.0)\n",
            "Collecting tensorboard<2.10,>=2.9 (from tensorflow==2.9.0)\n",
            "  Downloading tensorboard-2.9.1-py3-none-any.whl.metadata (1.9 kB)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.9.0) (0.37.1)\n",
            "Collecting tensorflow-estimator<2.10.0,>=2.9.0rc0 (from tensorflow==2.9.0)\n",
            "  Downloading tensorflow_estimator-2.9.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.9.0) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.9.0) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.9.0) (1.17.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow==2.9.0) (0.45.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.0) (2.27.0)\n",
            "Collecting google-auth-oauthlib<0.5,>=0.4.1 (from tensorboard<2.10,>=2.9->tensorflow==2.9.0)\n",
            "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.0) (3.7)\n",
            "Collecting protobuf>=3.9.2 (from tensorflow==2.9.0)\n",
            "  Downloading protobuf-3.19.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (787 bytes)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.0) (2.32.3)\n",
            "Collecting tensorboard-data-server<0.7.0,>=0.6.0 (from tensorboard<2.10,>=2.9->tensorflow==2.9.0)\n",
            "  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl.metadata (1.1 kB)\n",
            "Collecting tensorboard-plugin-wit>=1.6.0 (from tensorboard<2.10,>=2.9->tensorflow==2.9.0)\n",
            "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl.metadata (873 bytes)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.0) (3.1.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9.0) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9.0) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9.0) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow==2.9.0) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow==2.9.0) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow==2.9.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow==2.9.0) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow==2.9.0) (2024.12.14)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.10,>=2.9->tensorflow==2.9.0) (3.0.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9.0) (0.6.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow==2.9.0) (3.2.2)\n",
            "Downloading tensorflow-2.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (511.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m511.7/511.7 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
            "Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
            "Downloading keras-2.9.0-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m66.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard-2.9.1-py3-none-any.whl (5.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m62.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading protobuf-3.19.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m44.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_estimator-2.9.0-py2.py3-none-any.whl (438 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m438.7/438.7 kB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
            "Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m93.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.3/781.3 kB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tensorboard-plugin-wit, keras, flatbuffers, tensorflow-estimator, tensorboard-data-server, protobuf, keras-preprocessing, gast, google-auth-oauthlib, tensorboard, tensorflow\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 3.5.0\n",
            "    Uninstalling keras-3.5.0:\n",
            "      Successfully uninstalled keras-3.5.0\n",
            "  Attempting uninstall: flatbuffers\n",
            "    Found existing installation: flatbuffers 24.12.23\n",
            "    Uninstalling flatbuffers-24.12.23:\n",
            "      Successfully uninstalled flatbuffers-24.12.23\n",
            "  Attempting uninstall: tensorboard-data-server\n",
            "    Found existing installation: tensorboard-data-server 0.7.2\n",
            "    Uninstalling tensorboard-data-server-0.7.2:\n",
            "      Successfully uninstalled tensorboard-data-server-0.7.2\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 4.25.5\n",
            "    Uninstalling protobuf-4.25.5:\n",
            "      Successfully uninstalled protobuf-4.25.5\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.6.0\n",
            "    Uninstalling gast-0.6.0:\n",
            "      Successfully uninstalled gast-0.6.0\n",
            "  Attempting uninstall: google-auth-oauthlib\n",
            "    Found existing installation: google-auth-oauthlib 1.2.1\n",
            "    Uninstalling google-auth-oauthlib-1.2.1:\n",
            "      Successfully uninstalled google-auth-oauthlib-1.2.1\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.17.1\n",
            "    Uninstalling tensorboard-2.17.1:\n",
            "      Successfully uninstalled tensorboard-2.17.1\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.17.1\n",
            "    Uninstalling tensorflow-2.17.1:\n",
            "      Successfully uninstalled tensorflow-2.17.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-ai-generativelanguage 0.6.10 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-aiplatform 1.74.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-bigquery-connection 1.17.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-bigquery-storage 2.27.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-bigtable 2.27.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-datastore 2.20.2 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-firestore 2.19.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-functions 1.19.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-iam 2.17.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-language 2.16.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-pubsub 2.27.2 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-resource-manager 1.14.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-translate 3.19.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "googleapis-common-protos 1.66.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0.dev0,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "grpc-google-iam-v1 0.14.0 requires protobuf!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "grpcio-status 1.62.3 requires protobuf>=4.21.6, but you have protobuf 3.19.6 which is incompatible.\n",
            "pandas-gbq 0.26.1 requires google-auth-oauthlib>=0.7.0, but you have google-auth-oauthlib 0.4.6 which is incompatible.\n",
            "tensorflow-datasets 4.9.7 requires protobuf>=3.20, but you have protobuf 3.19.6 which is incompatible.\n",
            "tensorflow-metadata 1.13.1 requires protobuf<5,>=3.20.3, but you have protobuf 3.19.6 which is incompatible.\n",
            "tf-keras 2.17.0 requires tensorflow<2.18,>=2.17, but you have tensorflow 2.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed flatbuffers-1.12 gast-0.4.0 google-auth-oauthlib-0.4.6 keras-2.9.0 keras-preprocessing-1.1.2 protobuf-3.19.6 tensorboard-2.9.1 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.9.0 tensorflow-estimator-2.9.0\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "637ab74a0961434586541d7f0caaaa4e",
              "pip_warning": {
                "packages": [
                  "google"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (2.9.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python) (1.26.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install timm\n",
        "!pip install fairscale\n",
        "!pip install transformers\n",
        "!pip install requests\n",
        "!pip install accelerate\n",
        "!pip install diffusers\n",
        "!pip install einop\n",
        "!pip install safetensors\n",
        "!pip install voluptuous\n",
        "!pip install jax\n",
        "!pip install jaxlib\n",
        "!pip install peft\n",
        "!pip install deepface==0.0.90\n",
        "!pip install tensorflow==2.9.0\n",
        "!pip install keras\n",
        "!pip install opencv-python\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "09608f50-24e2-4860-b68a-320b25207f98",
      "metadata": {
        "id": "09608f50-24e2-4860-b68a-320b25207f98"
      },
      "source": [
        "## 导入"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "63e43e2c-c6f9-4981-8ac8-a8f89de845e5",
      "metadata": {
        "id": "63e43e2c-c6f9-4981-8ac8-a8f89de845e5"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import math\n",
        "import glob\n",
        "import shutil\n",
        "import subprocess\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from PIL import Image\n",
        "from tqdm.auto import tqdm\n",
        "from torchvision import transforms\n",
        "\n",
        "from transformers import CLIPTextModel, CLIPTokenizer, CLIPModel, CLIPProcessor\n",
        "\n",
        "from diffusers import (\n",
        "    AutoencoderKL,\n",
        "    DDPMScheduler,\n",
        "    UNet2DConditionModel,\n",
        "    DiffusionPipeline\n",
        ")\n",
        "from diffusers.optimization import get_scheduler\n",
        "from diffusers.training_utils import compute_snr\n",
        "\n",
        "from peft import LoraConfig, get_peft_model, PeftModel\n",
        "\n",
        "\n",
        "from deepface import DeepFace\n",
        "\n",
        "import cv2"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bbbf9948-94b5-463b-a8e7-f48d999762e3",
      "metadata": {
        "id": "bbbf9948-94b5-463b-a8e7-f48d999762e3"
      },
      "source": [
        "## 准备项目\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4ae237bf-6d30-4efa-b6a9-7a6d22827238",
      "metadata": {
        "id": "4ae237bf-6d30-4efa-b6a9-7a6d22827238"
      },
      "outputs": [],
      "source": [
        "project_name = \"Dog\"\n",
        "dataset_name = \"Dog\"\n",
        "\n",
        "root_dir = \"./\"\n",
        "main_dir = os.path.join(root_dir, \"SD\")\n",
        "\n",
        "project_dir = os.path.join(main_dir, project_name)\n",
        "\n",
        "\n",
        "images_folder = os.path.join(main_dir, \"Datasets\", dataset_name)\n",
        "prompts_folder = os.path.join(main_dir, \"Datasets\", \"prompts\")\n",
        "captions_folder = images_folder\n",
        "output_folder = os.path.join(project_dir, \"logs\")\n",
        "\n",
        "\n",
        "validation_prompt_name = \"validation_prompt.txt\"\n",
        "validation_prompt_path = os.path.join(prompts_folder, validation_prompt_name)\n",
        "\n",
        "\n",
        "model_path = os.path.join(project_dir, \"logs\", \"checkpoint-last\")\n",
        "\n",
        "\n",
        "zip_file = os.path.join(\"./\", \"data/Datasets.zip\")\n",
        "inference_path = os.path.join(project_dir, \"inference\")  # 保存推理结果的文件夹\n",
        "\n",
        "os.makedirs(images_folder, exist_ok=True)\n",
        "os.makedirs(prompts_folder, exist_ok=True)\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "os.makedirs(inference_path, exist_ok=True)\n",
        "\n",
        "# 检查并解压数据集\n",
        "print(\"正在检查并解压样例数据集...\")\n",
        "\n",
        "if not os.path.exists(zip_file):\n",
        "    print(\" 未找到数据集压缩文件 Datasets.zip！\")\n",
        "    print(\"请下载数据集:\\nhttps://github.com/Hoper-J/AI-Guide-and-Demos-zh_CN/blob/master/Demos/data/14/Datasets.zip\\n并放在 ./data 文件夹下\")\n",
        "else:\n",
        "    subprocess.run(f\"unzip -q -o {zip_file} -d {main_dir}\", shell=True)\n",
        "    print(f\" 项目 {project_name} 已准备好！\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2cdaa70a-5e3a-4b67-8743-3780d360d1a4",
      "metadata": {
        "id": "2cdaa70a-5e3a-4b67-8743-3780d360d1a4"
      },
      "source": [
        "## 定义一些有用的函数和类"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e0040ab7-0da7-4458-b627-af55dd701e67",
      "metadata": {
        "id": "e0040ab7-0da7-4458-b627-af55dd701e67"
      },
      "source": [
        "### 数据集"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "36c7d433-bb97-4cc1-a3b6-7c4c2ea22832",
      "metadata": {
        "id": "36c7d433-bb97-4cc1-a3b6-7c4c2ea22832"
      },
      "outputs": [],
      "source": [
        "IMAGE_EXTENSIONS = [\".png\", \".jpg\", \".jpeg\", \".webp\", \".bmp\", \".PNG\", \".JPG\", \".JPEG\", \".WEBP\", \".BMP\"]\n",
        "\n",
        "class Text2ImageDataset(torch.utils.data.Dataset):\n",
        "    \"\"\"\n",
        "    (1) 目标:\n",
        "        - 用于构建文本到图像模型的微调数据集\n",
        "    \"\"\"\n",
        "    def __init__(self, images_folder, captions_folder, transform, tokenizer):\n",
        "        \"\"\"\n",
        "        (2) 参数:\n",
        "            - images_folder: str, 图像文件夹路径\n",
        "            - captions_folder: str, 标注文件夹路径\n",
        "            - transform: function, 将原始图像转换为 torch.Tensor\n",
        "            - tokenizer: CLIPTokenizer, 将文本标注转为 word ids\n",
        "        \"\"\"\n",
        "        # 初始化图像路径列表，并根据指定的扩展名找到所有图像文件\n",
        "        self.image_paths = []\n",
        "        for ext in IMAGE_EXTENSIONS:\n",
        "            self.image_paths.extend(glob.glob(os.path.join(images_folder, f\"*{ext}\")))\n",
        "        self.image_paths = sorted(self.image_paths)\n",
        "\n",
        "        # 加载对应的文本标注，依次读取每个文本文件中的内容\n",
        "        caption_paths = sorted(glob.glob(os.path.join(captions_folder, \"*.txt\")))\n",
        "        captions = []\n",
        "        for p in caption_paths:\n",
        "            with open(p, \"r\", encoding=\"utf-8\") as f:\n",
        "                captions.append(f.readline().strip())\n",
        "\n",
        "        # 确保图像和文本标注数量一致\n",
        "        if len(captions) != len(self.image_paths):\n",
        "            raise ValueError(\"图像数量与文本标注数量不一致，请检查数据集。\")\n",
        "\n",
        "        # 使用 tokenizer 将文本标注转换为 word ids\n",
        "        inputs = tokenizer(\n",
        "            captions, max_length=tokenizer.model_max_length, padding=\"max_length\", truncation=True, return_tensors=\"pt\"\n",
        "        )\n",
        "        self.input_ids = inputs.input_ids\n",
        "        self.transform = transform\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.image_paths[idx]\n",
        "        input_id = self.input_ids[idx]\n",
        "        try:\n",
        "            # 加载图像并将其转换为 RGB 模式，然后应用数据增强\n",
        "            image = Image.open(img_path).convert(\"RGB\")\n",
        "            tensor = self.transform(image)\n",
        "        except Exception as e:\n",
        "            print(f\" 无法加载图像路径: {img_path}, 错误: {e}\")\n",
        "            # 返回一个全零的张量和空的输入 ID 以避免崩溃\n",
        "            tensor = torch.zeros((3, resolution, resolution))\n",
        "            input_id = torch.zeros_like(input_id)\n",
        "\n",
        "        return tensor, input_id  # 返回处理后的图像和相应的文本标注\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1c18b966-f7e0-415d-b49a-70773a33fb7b",
      "metadata": {
        "id": "1c18b966-f7e0-415d-b49a-70773a33fb7b"
      },
      "source": [
        "### 加载 LoRA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e413064d-c177-4857-944f-0030ff51089c",
      "metadata": {
        "id": "e413064d-c177-4857-944f-0030ff51089c"
      },
      "outputs": [],
      "source": [
        "def prepare_lora_model(lora_config, pretrained_model_name_or_path, model_path=None, resume=False, merge_lora=False):\n",
        "    \"\"\"\n",
        "    (1) 目标:\n",
        "        - 加载完整的 Stable Diffusion 模型，包括 LoRA 层，并根据需要合并 LoRA 权重。这包括 Tokenizer、噪声调度器、UNet、VAE 和文本编码器。\n",
        "\n",
        "    (2) 参数:\n",
        "        - lora_config: LoraConfig, LoRA 的配置对象\n",
        "        - pretrained_model_name_or_path: str, Hugging Face 上的模型名称或路径\n",
        "        - model_path: str, 预训练模型的路径\n",
        "        - resume: bool, 是否从上一次训练中恢复\n",
        "        - merge_lora: bool, 是否在推理时合并 LoRA 权重\n",
        "\n",
        "    (3) 返回:\n",
        "        - tokenizer: CLIPTokenizer\n",
        "        - noise_scheduler: DDPMScheduler\n",
        "        - unet: UNet2DConditionModel\n",
        "        - vae: AutoencoderKL\n",
        "        - text_encoder: CLIPTextModel\n",
        "    \"\"\"\n",
        "    # 加载噪声调度器，用于控制扩散模型的噪声添加和移除过程\n",
        "    noise_scheduler = DDPMScheduler.from_pretrained(pretrained_model_name_or_path, subfolder=\"scheduler\")\n",
        "\n",
        "    # 加载 Tokenizer，用于将文本标注转换为 tokens\n",
        "    tokenizer = CLIPTokenizer.from_pretrained(\n",
        "        pretrained_model_name_or_path,\n",
        "        subfolder=\"tokenizer\"\n",
        "    )\n",
        "\n",
        "    # 加载 CLIP 文本编码器，用于将文本标注转换为特征向量\n",
        "    text_encoder = CLIPTextModel.from_pretrained(\n",
        "        pretrained_model_name_or_path,\n",
        "        torch_dtype=weight_dtype,\n",
        "        subfolder=\"text_encoder\"\n",
        "    )\n",
        "\n",
        "    # 加载 VAE 模型，用于在扩散模型中处理图像的潜在表示\n",
        "    vae = AutoencoderKL.from_pretrained(\n",
        "        pretrained_model_name_or_path,\n",
        "        subfolder=\"vae\"\n",
        "    )\n",
        "\n",
        "    # 加载 UNet 模型，负责处理扩散模型中的图像生成和推理过程\n",
        "    unet = UNet2DConditionModel.from_pretrained(\n",
        "        pretrained_model_name_or_path,\n",
        "        torch_dtype=weight_dtype,\n",
        "        subfolder=\"unet\"\n",
        "    )\n",
        "\n",
        "    # 如果设置为继续训练，则加载上一次的模型权重\n",
        "    if resume:\n",
        "        if model_path is None or not os.path.exists(model_path):\n",
        "            raise ValueError(\"当 resume 设置为 True 时，必须提供有效的 model_path\")\n",
        "        # 使用 PEFT 的 from_pretrained 方法加载 LoRA 模型\n",
        "        text_encoder = PeftModel.from_pretrained(text_encoder, os.path.join(model_path, \"text_encoder\"))\n",
        "        unet = PeftModel.from_pretrained(unet, os.path.join(model_path, \"unet\"))\n",
        "\n",
        "        # 确保 UNet 的可训练参数的 requires_grad 为 True\n",
        "        for param in unet.parameters():\n",
        "            if param.requires_grad is False:\n",
        "                param.requires_grad = True\n",
        "\n",
        "        # 确保文本编码器的可训练参数的 requires_grad 为 True\n",
        "        for param in text_encoder.parameters():\n",
        "            if param.requires_grad is False:\n",
        "                param.requires_grad = True\n",
        "\n",
        "        print(f\" 已从 {model_path} 恢复模型权重\")\n",
        "\n",
        "    else:\n",
        "        # 将 LoRA 配置应用到 text_encoder 和 unet\n",
        "        text_encoder = get_peft_model(text_encoder, lora_config)\n",
        "        unet = get_peft_model(unet, lora_config)\n",
        "\n",
        "        # 打印可训练参数数量\n",
        "        print(\" Text Encoder 可训练参数:\")\n",
        "        text_encoder.print_trainable_parameters()\n",
        "        print(\" UNet 可训练参数:\")\n",
        "        unet.print_trainable_parameters()\n",
        "\n",
        "    if merge_lora:\n",
        "        # 合并 LoRA 权重到基础模型，仅在推理时调用\n",
        "        text_encoder = text_encoder.merge_and_unload()\n",
        "        unet = unet.merge_and_unload()\n",
        "\n",
        "        # 切换为评估模式\n",
        "        text_encoder.eval()\n",
        "        unet.eval()\n",
        "\n",
        "    # 冻结 VAE 参数\n",
        "    vae.requires_grad_(False)\n",
        "\n",
        "    # 将模型移动到 GPU 上并设置权重的数据类型\n",
        "    unet.to(DEVICE, dtype=weight_dtype)\n",
        "    vae.to(DEVICE, dtype=weight_dtype)\n",
        "    text_encoder.to(DEVICE, dtype=weight_dtype)\n",
        "\n",
        "    return tokenizer, noise_scheduler, unet, vae, text_encoder"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "19f62fe6-8b07-4210-84ed-7c4f4368c179",
      "metadata": {
        "id": "19f62fe6-8b07-4210-84ed-7c4f4368c179"
      },
      "source": [
        "### 准备优化器"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "491cd8f9-678f-464b-a386-3dd3eca3b70e",
      "metadata": {
        "id": "491cd8f9-678f-464b-a386-3dd3eca3b70e"
      },
      "outputs": [],
      "source": [
        "def prepare_optimizer(unet, text_encoder, unet_learning_rate=5e-4, text_encoder_learning_rate=1e-4):\n",
        "    \"\"\"\n",
        "    (1) 目标:\n",
        "        - 为 UNet 和文本编码器的可训练参数分别设置优化器，并指定不同的学习率。\n",
        "\n",
        "    (2) 参数:\n",
        "        - unet: UNet2DConditionModel, Hugging Face 的 UNet 模型\n",
        "        - text_encoder: CLIPTextModel, Hugging Face 的文本编码器\n",
        "        - unet_learning_rate: float, UNet 的学习率\n",
        "        - text_encoder_learning_rate: float, 文本编码器的学习率\n",
        "\n",
        "    (3) 返回:\n",
        "        - 输出: 优化器 Optimizer\n",
        "    \"\"\"\n",
        "    # 筛选出 UNet 中需要训练的 Lora 层参数\n",
        "    unet_lora_layers = [p for p in unet.parameters() if p.requires_grad]\n",
        "\n",
        "    # 筛选出文本编码器中需要训练的 Lora 层参数\n",
        "    text_encoder_lora_layers = [p for p in text_encoder.parameters() if p.requires_grad]\n",
        "\n",
        "    # 将需要训练的参数分组并设置不同的学习率\n",
        "    trainable_params = [\n",
        "        {\"params\": unet_lora_layers, \"lr\": unet_learning_rate},\n",
        "        {\"params\": text_encoder_lora_layers, \"lr\": text_encoder_learning_rate}\n",
        "    ]\n",
        "\n",
        "    # 使用 AdamW 优化器\n",
        "    optimizer = torch.optim.AdamW(trainable_params)\n",
        "\n",
        "    return optimizer"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "574c7c21-5dc3-484a-8fa1-5689be53684f",
      "metadata": {
        "id": "574c7c21-5dc3-484a-8fa1-5689be53684f"
      },
      "source": [
        "### 定义 collate_fn 函数"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "25bec1c8-4535-4cd4-9c97-e571da1dc861",
      "metadata": {
        "id": "25bec1c8-4535-4cd4-9c97-e571da1dc861"
      },
      "outputs": [],
      "source": [
        "def collate_fn(examples):\n",
        "    pixel_values = []\n",
        "    input_ids = []\n",
        "\n",
        "    for tensor, input_id in examples:\n",
        "        pixel_values.append(tensor)\n",
        "        input_ids.append(input_id)\n",
        "\n",
        "    pixel_values = torch.stack(pixel_values, dim=0).float()\n",
        "    input_ids = torch.stack(input_ids, dim=0)\n",
        "\n",
        "    # 如果你喜欢列表推导式的话，使用下面的方法\n",
        "    #pixel_values = torch.stack([example[0] for example in examples], dim=0).float()\n",
        "    #input_ids = torch.stack([example[1] for example in examples], dim=0)\n",
        "\n",
        "    return {\"pixel_values\": pixel_values, \"input_ids\": input_ids}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "838f6274-fb4b-4b7c-9936-06252f45f42e",
      "metadata": {
        "id": "838f6274-fb4b-4b7c-9936-06252f45f42e"
      },
      "source": [
        "## 参数设置\n",
        "\n",
        "### 1. 设备配置"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bfe24c04-4638-466a-a909-8e44e7b43560",
      "metadata": {
        "id": "bfe24c04-4638-466a-a909-8e44e7b43560"
      },
      "outputs": [],
      "source": [
        "# 设备配置\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# For Mac M1, M2...\n",
        "# DEVICE = torch.device(\"mps\" if torch.backends.mps.is_available() else (\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
        "\n",
        "print(f\"🖥 当前使用的设备: {DEVICE}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "561a41d7-f426-406c-9fbd-9ba3afe5ed7d",
      "metadata": {
        "id": "561a41d7-f426-406c-9fbd-9ba3afe5ed7d"
      },
      "source": [
        "### 2. 图像预处理与数据增强"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3967ac77-7b2d-410d-975e-af9433145e6b",
      "metadata": {
        "id": "3967ac77-7b2d-410d-975e-af9433145e6b"
      },
      "outputs": [],
      "source": [
        "# 训练图像的分辨率\n",
        "resolution = 512\n",
        "\n",
        "# 数据增强操作\n",
        "train_transform = transforms.Compose(\n",
        "    [\n",
        "        transforms.Resize(resolution, interpolation=transforms.InterpolationMode.BILINEAR),  # 调整图像大小\n",
        "        transforms.CenterCrop(resolution),  # 中心裁剪图像\n",
        "        transforms.RandomHorizontalFlip(),  # 随机水平翻转\n",
        "        transforms.ToTensor(),  # 将图像转换为张量\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f3c9aec3-6c15-4e98-bf83-3b423c5dab40",
      "metadata": {
        "id": "f3c9aec3-6c15-4e98-bf83-3b423c5dab40"
      },
      "source": [
        "### 3. 模型与训练参数配置"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8a050558-444c-4d7c-bccd-4b001829fad7",
      "metadata": {
        "id": "8a050558-444c-4d7c-bccd-4b001829fad7"
      },
      "outputs": [],
      "source": [
        "# 训练相关参数\n",
        "train_batch_size = 2  # 训练批次大小，即每次训练中处理的样本数量\n",
        "weight_dtype = torch.bfloat16  # 权重数据类型，使用 bfloat16 以节省内存并加快计算速度\n",
        "snr_gamma = 5  # SNR 参数，用于信噪比加权损失的调节系数\n",
        "\n",
        "# 设置随机数种子以确保可重复性\n",
        "seed = 1126  # 随机数种子\n",
        "torch.manual_seed(seed)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "# Stable Diffusion LoRA 的微调参数\n",
        "\n",
        "# 优化器参数\n",
        "unet_learning_rate = 1e-4  # UNet 的学习率，控制 UNet 参数更新的步长\n",
        "text_encoder_learning_rate = 1e-4  # 文本编码器的学习率，控制文本嵌入层的参数更新步长\n",
        "\n",
        "# 学习率调度器参数\n",
        "lr_scheduler_name = \"cosine_with_restarts\"  # 设置学习率调度器为 Cosine annealing with restarts，逐渐减少学习率并定期重启\n",
        "lr_warmup_steps = 100  # 学习率预热步数，在最初的 100 步中逐渐增加学习率到最大值\n",
        "max_train_steps = 200  # 总训练步数，决定了整个训练过程的迭代次数\n",
        "num_cycles = 3  # Cosine 调度器的周期数量，在训练期间会重复 3 次学习率周期性递减并重启\n",
        "\n",
        "# 预训练的 Stable Diffusion 模型路径，用于加载模型进行微调\n",
        "pretrained_model_name_or_path = \"stablediffusionapi/cyberrealistic-41\"\n",
        "\n",
        "# LoRA 配置\n",
        "lora_config = LoraConfig(\n",
        "    r=32,  # LoRA 的秩，即低秩矩阵的维度，决定了参数调整的自由度\n",
        "    lora_alpha=16,  # 缩放系数，控制 LoRA 权重对模型的影响\n",
        "    target_modules=[\n",
        "        \"q_proj\", \"v_proj\", \"k_proj\", \"out_proj\",  # 指定 Text encoder 的 LoRA 应用对象（用于调整注意力机制中的投影矩阵）\n",
        "        \"to_k\", \"to_q\", \"to_v\", \"to_out.0\"  # 指定 UNet 的 LoRA 应用对象（用于调整 UNet 中的注意力机制）\n",
        "    ],\n",
        "    lora_dropout=0  # LoRA dropout 概率，0 表示不使用 dropout\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1fdeedb5-b8ce-4590-9dcc-559729edebd2",
      "metadata": {
        "id": "1fdeedb5-b8ce-4590-9dcc-559729edebd2"
      },
      "source": [
        "## 微调前的准备"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6e46cd03-d4bd-4094-88f3-036fcf16b872",
      "metadata": {
        "id": "6e46cd03-d4bd-4094-88f3-036fcf16b872"
      },
      "source": [
        "### 1. 数据集"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7d335cfc-007d-4d47-878b-432cf8d1f4ff",
      "metadata": {
        "id": "7d335cfc-007d-4d47-878b-432cf8d1f4ff"
      },
      "outputs": [],
      "source": [
        "# 初始化 tokenizer，用于加载数据集\n",
        "tokenizer = CLIPTokenizer.from_pretrained(\n",
        "    pretrained_model_name_or_path,\n",
        "    subfolder=\"tokenizer\"\n",
        ")\n",
        "\n",
        "# 准备数据集\n",
        "dataset = Text2ImageDataset(\n",
        "    images_folder=images_folder,\n",
        "    captions_folder=captions_folder,\n",
        "    transform=train_transform,\n",
        "    tokenizer=tokenizer,\n",
        ")\n",
        "\n",
        "train_dataloader = torch.utils.data.DataLoader(\n",
        "    dataset,\n",
        "    shuffle=True,\n",
        "    collate_fn=collate_fn,\n",
        "    batch_size=train_batch_size,\n",
        "    num_workers=8,\n",
        ")\n",
        "\n",
        "print(\"✅ 数据集准备完成！\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "db606893-440b-431b-bdcc-f81695d3d679",
      "metadata": {
        "id": "db606893-440b-431b-bdcc-f81695d3d679"
      },
      "source": [
        "### 2. 模型和优化器"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0d00a8bf-4103-4e22-93e5-14e749a84376",
      "metadata": {
        "id": "0d00a8bf-4103-4e22-93e5-14e749a84376"
      },
      "outputs": [],
      "source": [
        "# 准备模型\n",
        "tokenizer, noise_scheduler, unet, vae, text_encoder = prepare_lora_model(\n",
        "    lora_config,\n",
        "    pretrained_model_name_or_path,\n",
        "    model_path,\n",
        "    resume=False,  # 根据需要设置为 True 以从 checkpoint 恢复\n",
        "    merge_lora=False  # 是否合并 LoRA 权重\n",
        ")\n",
        "\n",
        "# 准备优化器\n",
        "optimizer = prepare_optimizer(\n",
        "    unet,\n",
        "    text_encoder,\n",
        "    unet_learning_rate=unet_learning_rate,\n",
        "    text_encoder_learning_rate=text_encoder_learning_rate\n",
        ")\n",
        "\n",
        "# 设置学习率调度器\n",
        "lr_scheduler = get_scheduler(\n",
        "    lr_scheduler_name,\n",
        "    optimizer=optimizer,\n",
        "    num_warmup_steps=lr_warmup_steps,\n",
        "    num_training_steps=max_train_steps,\n",
        "    num_cycles=num_cycles\n",
        ")\n",
        "\n",
        "print(\" 模型和优化器准备完成！可以开始训练。\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d8f3f649-bc32-441a-93b0-4fc784e0fa3b",
      "metadata": {
        "id": "d8f3f649-bc32-441a-93b0-4fc784e0fa3b"
      },
      "source": [
        "## 开始微调"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4117f19a-fd07-4828-9c0a-1b91ae658986",
      "metadata": {
        "id": "4117f19a-fd07-4828-9c0a-1b91ae658986"
      },
      "outputs": [],
      "source": [
        "# 禁用并行化，避免警告\n",
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
        "\n",
        "# 初始化\n",
        "global_step = 0\n",
        "best_face_score = float(\"inf\")  # 初始化为正无穷大，存储最佳面部相似度分数\n",
        "\n",
        "# 进度条显示训练进度\n",
        "progress_bar = tqdm(\n",
        "    range(max_train_steps),  # 根据 num_training_steps 设置\n",
        "    desc=\"训练步骤\",\n",
        ")\n",
        "\n",
        "# 训练循环\n",
        "for epoch in range(math.ceil(max_train_steps / len(train_dataloader))):\n",
        "    # 如果你想在训练中增加评估，那在循环中增加 train() 是有必要的\n",
        "    unet.train()\n",
        "    text_encoder.train()\n",
        "\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "        if global_step >= max_train_steps:\n",
        "            break\n",
        "\n",
        "        # 编码图像为潜在表示（latent）\n",
        "        latents = vae.encode(batch[\"pixel_values\"].to(DEVICE, dtype=weight_dtype)).latent_dist.sample()\n",
        "        latents = latents * vae.config.scaling_factor  # 根据 VAE 的缩放因子调整潜在空间\n",
        "\n",
        "        # 为潜在表示添加噪声，生成带噪声的图像\n",
        "        noise = torch.randn_like(latents)  # 生成与潜在表示相同形状的随机噪声\n",
        "        timesteps = torch.randint(0, noise_scheduler.config.num_train_timesteps, (latents.shape[0],), device=DEVICE).long()\n",
        "        noisy_latents = noise_scheduler.add_noise(latents, noise, timesteps)\n",
        "\n",
        "        # 获取文本的嵌入表示\n",
        "        encoder_hidden_states = text_encoder(batch[\"input_ids\"].to(DEVICE))[0]\n",
        "\n",
        "        # 计算目标值\n",
        "        if noise_scheduler.config.prediction_type == \"epsilon\":\n",
        "            target = noise  # 预测噪声\n",
        "        elif noise_scheduler.config.prediction_type == \"v_prediction\":\n",
        "            target = noise_scheduler.get_velocity(latents, noise, timesteps)  # 预测速度向量\n",
        "\n",
        "        # UNet 模型预测\n",
        "        model_pred = unet(noisy_latents, timesteps, encoder_hidden_states)[0]\n",
        "\n",
        "        # 计算损失\n",
        "        if not snr_gamma:\n",
        "            loss = F.mse_loss(model_pred.float(), target.float(), reduction=\"mean\")\n",
        "        else:\n",
        "            # 计算信噪比 (SNR) 并根据 SNR 加权 MSE 损失\n",
        "            snr = compute_snr(noise_scheduler, timesteps)\n",
        "            mse_loss_weights = torch.stack([snr, snr_gamma * torch.ones_like(timesteps)], dim=1).min(dim=1)[0]\n",
        "            if noise_scheduler.config.prediction_type == \"epsilon\":\n",
        "                mse_loss_weights = mse_loss_weights / snr\n",
        "            elif noise_scheduler.config.prediction_type == \"v_prediction\":\n",
        "                mse_loss_weights = mse_loss_weights / (snr + 1)\n",
        "\n",
        "            # 计算加权的 MSE 损失\n",
        "            loss = F.mse_loss(model_pred.float(), target.float(), reduction=\"none\")\n",
        "            loss = loss.mean(dim=list(range(1, len(loss.shape)))) * mse_loss_weights\n",
        "            loss = loss.mean()\n",
        "\n",
        "        # 反向传播\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        lr_scheduler.step()\n",
        "        optimizer.zero_grad()\n",
        "        progress_bar.update(1)\n",
        "        global_step += 1\n",
        "\n",
        "        # 打印训练损失\n",
        "        if global_step % 100 == 0 or global_step == max_train_steps:\n",
        "            print(f\" 步骤 {global_step}, 损失: {loss.item()}\")\n",
        "\n",
        "        # 保存中间检查点，当前简单设置为每 500 步保存一次\n",
        "        if global_step % 500 == 0:\n",
        "            save_path = os.path.join(output_folder, f\"checkpoint-{global_step}\")\n",
        "            os.makedirs(save_path, exist_ok=True)\n",
        "\n",
        "            # 使用 save_pretrained 保存 PeftModel\n",
        "            unet.save_pretrained(os.path.join(save_path, \"unet\"))\n",
        "            text_encoder.save_pretrained(os.path.join(save_path, \"text_encoder\"))\n",
        "            print(f\" 已保存中间模型到 {save_path}\")\n",
        "\n",
        "# 保存最终模型到 checkpoint-last\n",
        "save_path = os.path.join(output_folder, \"checkpoint-last\")\n",
        "os.makedirs(save_path, exist_ok=True)\n",
        "unet.save_pretrained(os.path.join(save_path, \"unet\"))\n",
        "text_encoder.save_pretrained(os.path.join(save_path, \"text_encoder\"))\n",
        "print(f\" 已保存最终模型到 {save_path}\")\n",
        "\n",
        "print(\" 微调完成！\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0d83c69b-bb4a-430b-8580-f897874a69eb",
      "metadata": {
        "id": "0d83c69b-bb4a-430b-8580-f897874a69eb"
      },
      "source": [
        "## 生成图像和测试\n",
        "\n",
        "### 加载用于验证的 prompts\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "53cce6c3-d106-4317-8f28-4dc7be4c7b9d",
      "metadata": {
        "id": "53cce6c3-d106-4317-8f28-4dc7be4c7b9d"
      },
      "outputs": [],
      "source": [
        "def load_validation_prompts(validation_prompt_path):\n",
        "    \"\"\"\n",
        "    (1) 目标:\n",
        "        - 加载验证提示文本。\n",
        "\n",
        "    (2) 参数:\n",
        "        - validation_prompt_path: str, 验证提示文件的路径\n",
        "\n",
        "    (3) 返回:\n",
        "        - validation_prompt: list, 验证提示的字符串列表，每一行就是一个prompt\n",
        "    \"\"\"\n",
        "    with open(validation_prompt_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        validation_prompt = [line.strip() for line in f.readlines()]\n",
        "    return validation_prompt"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0908312c-d673-4f23-9039-e42b01f05f45",
      "metadata": {
        "id": "0908312c-d673-4f23-9039-e42b01f05f45"
      },
      "source": [
        "### 定义生成图像的函数"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4b41e53b-7222-4cff-97de-5d8a7bef482e",
      "metadata": {
        "id": "4b41e53b-7222-4cff-97de-5d8a7bef482e"
      },
      "outputs": [],
      "source": [
        "def generate_images(pipeline, prompts, num_inference_steps=50, guidance_scale=7.5, output_folder=\"inference\", generator=None):\n",
        "    \"\"\"\n",
        "    (1) 目标:\n",
        "        - 使用 DiffusionPipeline 生成图像，保存到指定文件夹并返回生成的图像列表。\n",
        "\n",
        "    (2) 参数:\n",
        "        - pipeline: DiffusionPipeline, 已加载并配置好的 Pipeline\n",
        "        - prompts: list, 文本提示列表\n",
        "        - num_inference_steps: int, 推理步骤数，越高图像质量越好，但推理时间也会增加\n",
        "        - guidance_scale: float, 决定文本提示对生成图像的影响程度\n",
        "        - output_folder: str, 保存生成图像的文件夹路径\n",
        "        - generator: torch.Generator, 控制生成随机数的种子，确保图像生成的一致性。如果不提供，生成的图像每次可能不同\n",
        "\n",
        "    (3) 返回:\n",
        "        - 生成的图像列表，同时图像也会保存到指定文件夹。\n",
        "    \"\"\"\n",
        "    print(\" 正在生成图像...\")\n",
        "    os.makedirs(output_folder, exist_ok=True)\n",
        "    generated_images = []\n",
        "\n",
        "    for i, prompt in enumerate(tqdm(prompts, desc=\"生成图像中\")):\n",
        "        # 使用 pipeline 生成图像\n",
        "        image = pipeline(prompt, num_inference_steps=num_inference_steps, guidance_scale=guidance_scale, generator=generator).images[0]\n",
        "\n",
        "        # 保存图像到指定文件夹\n",
        "        save_file = os.path.join(output_folder, f\"generated_{i+1}.png\")\n",
        "        image.save(save_file)\n",
        "\n",
        "        # 将图像保存到列表中，稍后返回\n",
        "        generated_images.append(image)\n",
        "\n",
        "    print(f\" 已生成并保存 {len(prompts)} 张图像到 {output_folder}\")\n",
        "\n",
        "    return generated_images"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f71ff0b1-f183-4f45-b333-405577ce5958",
      "metadata": {
        "id": "f71ff0b1-f183-4f45-b333-405577ce5958"
      },
      "source": [
        "### 定义评估函数"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fcc5cfa8-7186-431f-923c-ca40d7a120db",
      "metadata": {
        "id": "fcc5cfa8-7186-431f-923c-ca40d7a120db"
      },
      "outputs": [],
      "source": [
        "def evaluate(lora_config):\n",
        "    \"\"\"\n",
        "    加载模型、生成图像并评估。\n",
        "\n",
        "    主要步骤：\n",
        "    1. 加载验证文本提示（prompts）用于生成图像。\n",
        "    2. 加载和准备 LoRA 微调后的模型。\n",
        "    3. 使用 DiffusionPipeline 生成图像。\n",
        "    4. 评估生成图像的 CLIP 评分。\n",
        "    5. 打印评估结果。\n",
        "    \"\"\"\n",
        "    print(\" 加载验证提示...\")\n",
        "    validation_prompts = load_validation_prompts(validation_prompt_path)\n",
        "\n",
        "    print(\" 准备 LoRA 模型...\")\n",
        "    # 准备 LoRA 模型（用于推理，合并权重）\n",
        "    tokenizer, noise_scheduler, unet, vae, text_encoder = prepare_lora_model(\n",
        "        lora_config,\n",
        "        pretrained_model_name_or_path,\n",
        "        model_path=model_path,\n",
        "        resume=True,  # 从检查点恢复\n",
        "        merge_lora=True  # 合并 LoRA 权重\n",
        "    )\n",
        "\n",
        "    # 创建 DiffusionPipeline 并更新其组件\n",
        "    print(\" 创建 DiffusionPipeline...\")\n",
        "    pipeline = DiffusionPipeline.from_pretrained(\n",
        "        pretrained_model_name_or_path,\n",
        "        unet=unet,  # 传递基础模型\n",
        "        text_encoder=text_encoder,  # 传递基础模型\n",
        "        torch_dtype=weight_dtype,\n",
        "        safety_checker=None,\n",
        "    )\n",
        "    pipeline = pipeline.to(DEVICE)\n",
        "\n",
        "    # 加载 CLIP 模型和处理器\n",
        "    print(\" 加载 CLIP 模型...\")\n",
        "    clip_model_name = \"openai/clip-vit-base-patch32\"\n",
        "    clip_model = CLIPModel.from_pretrained(clip_model_name).to(DEVICE)\n",
        "    clip_processor = CLIPProcessor.from_pretrained(clip_model_name)\n",
        "\n",
        "    # CLIP 模型设置为评估模式\n",
        "    clip_model.eval()\n",
        "\n",
        "    # 设置随机数种子\n",
        "    generator = torch.Generator(device=DEVICE)\n",
        "    generator.manual_seed(seed)\n",
        "\n",
        "    # 生成图像\n",
        "    generated_images = generate_images(\n",
        "        pipeline=pipeline,\n",
        "        prompts=validation_prompts,\n",
        "        num_inference_steps=30,\n",
        "        guidance_scale=7.5,\n",
        "        output_folder=inference_path,\n",
        "        generator=generator\n",
        "    )\n",
        "\n",
        "    # 评估生成的图像\n",
        "    clip_score = 0  # 初始化评估分数\n",
        "    print(\" 正在计算评估分数...\")\n",
        "\n",
        "    for i, image in enumerate(tqdm(generated_images, desc=\"评估图像中\")):\n",
        "        # 计算 CLIP 分数\n",
        "        current_prompt = validation_prompts[i]\n",
        "        inputs = clip_processor(text=current_prompt, images=image, return_tensors=\"pt\").to(DEVICE)\n",
        "        with torch.no_grad():\n",
        "            outputs = clip_model(**inputs)\n",
        "        sim = outputs.logits_per_image\n",
        "        clip_score += sim.item()\n",
        "\n",
        "    # 计算平均 CLIP 评分\n",
        "    clip_score /= len(validation_prompts) if len(validation_prompts) > 0 else 1\n",
        "    print(\" 评估完成！\")\n",
        "\n",
        "    # 打印评估结果\n",
        "    print(f\" CLIP 评分 (平均相似度): {clip_score:.4f} (越高越好，表示生成图像与文本提示的相关性更强)\")\n",
        "\n",
        "# 调用函数执行\n",
        "evaluate(lora_config)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "21673bd9-ac20-47c6-9195-456fd05c7df5",
      "metadata": {
        "id": "21673bd9-ac20-47c6-9195-456fd05c7df5"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
